#################################################################
# Another shell script that set up the settings
# for your dag, including python scripts/arguments,
# where err/log/out are dumped, memories/disks/CPU
# resquest, etc.
#
# By default,
# In cobalt, time limit is 2 days, 2 GB (?).
# In umd condor, no time limit, 1 GB
#
# NOTE:: MAKE SURE NONE OF THE PATHS HERE POINTS TO I3HOME
#        ALL PATHS MUST POINT TO EITHER /data/condor_build/ OR
#        /data/i3store0/ OR /data/i3scratch0/
################################################################

## Will your job take longer than 12 hours or need gpu?
## Then un-comment one of these.
# +AccountingGroup="long.elims" ## its not accepted in wisc anymore
# +AccountingGroup="gpu.elims"

## Jobs requiring more than 1GB of memory or 1CPU can add:
#request_cpus = <num_cpus>
#request_memory = 1000
#<mem_in_MB> (default 1GB in umd, 2GB in wisc)
#request_disk = <disk_in_KB>

# Run the environment script from icetray before anything else
executable = /data/condor_builds/users/elims/software/ir041102/build/env-shell.sh

# Where the log, out, err files will live
initialdir     = /data/i3store0/users/jevans96/point_source_analysis/distributed_outputs/logs/
output         = $(initialdir)$(Jobname).$(Cluster).out
error          = $(initialdir)$(Jobname).$(Cluster).err

# Only 1 log file for all jobs
log = /data/i3store0/users/jevans96/point_source_analysis/distributed_outputs/out_err/$(Jobname).log

# Other condor stuff
notification   = never
getenv         = true
universe       = vanilla

# Submit !
Arguments = $(command)
queue
